
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Probability and Random Variables &#8212; The Principles of Statistical Modelling</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '2.prob-random-vars';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Defining a Statistical Model" href="3.define-stat-models.html" />
    <link rel="prev" title="Understanding Variance" href="1.understanding-variance.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="The Principles of Statistical Modelling - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="The Principles of Statistical Modelling - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.understanding-variance.html">Understanding Variance</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Probability and Random Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.define-stat-models.html">Defining a Statistical Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.model-elements.html">Elements of a Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="5.model-process.html">The Modelling Process</a></li>
<li class="toctree-l1"><a class="reference internal" href="summary.html">Summary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/PCHN63101-Advanced-Data-Skills/principles-stat-modelling" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/PCHN63101-Advanced-Data-Skills/principles-stat-modelling/issues/new?title=Issue%20on%20page%20%2F2.prob-random-vars.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/2.prob-random-vars.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Probability and Random Variables</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-variables">Random Variables</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-random-variables">Discrete Random Variables</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-random-variables">Continuous Random Variables</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-expected-value-of-a-distribution">The Expected Value of a Distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-variance-of-a-distribution">The Variance of a Distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-are-the-expected-value-and-variance-important">Why are the Expected Value and Variance Important?</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="probability-and-random-variables">
<h1>Probability and Random Variables<a class="headerlink" href="#probability-and-random-variables" title="Link to this heading">#</a></h1>
<p>We have now established that <em>variance</em> is the key property that we wish to capture from any given dataset. The fact that measured values differ from datapoint-to-datapoint implies an inherent <em>randomess</em> and <em>uncertainty</em> to real-world data. As such, in order to say anything about the variance in our data, we need some means of formalising this randomness. This formalisation comes from the world of <em>probability</em>.</p>
<div class="tip admonition">
<p class="admonition-title">The Meaning of “Randomness”</p>
<p>Unlike the common understanding of the term, <em>randomness</em> in probability does not mean completely unstructured and unpredictable. In everyday speech, when we say that something happened “randomly”, that is often taken as meaning that it could not have been predicted. However, in the more formal world of probability, the term <em>random</em> has a very specific definition that means something that is unpredictable in the short term, but has a <em>predictable regularity</em> over the long term. This is captured within the concept of a <em>random variable</em>.</p>
</div>
<section id="random-variables">
<h2>Random Variables<a class="headerlink" href="#random-variables" title="Link to this heading">#</a></h2>
<p>A <em>random variable</em> refers to any variable whos value changes with each measurement, but whos behaviour over time adheres to a known <em>probability distribution</em>. This is an important concept because every value that we measure as part of an experiment is concptualised as a realisation of a given random variable. For instance, we would treat <em>reaction time</em> as a random variable, with each measured value of reaction time representing a realistion of that random variable. Implicit in this is the idea that reaction time adheres to some probability distribution and that our experiment is simply the process of sampling value from that distribution.</p>
<p>In general, there are two different classes of random variable: <em>discrete</em> and <em>continuous</em>. This is an important distinction because one of the first things we need to do when analysing a dataset is determine which of the outcome variables are <em>discrete</em> and which are <em>continuous</em>. This will then dictate the range of models that are possible.</p>
<section id="discrete-random-variables">
<h3>Discrete Random Variables<a class="headerlink" href="#discrete-random-variables" title="Link to this heading">#</a></h3>
<p>The first class of random variables concern those where the number of possible outcomes is <em>finite</em>. For instance, tossing a coin and seeing whether the outcome is either heads or tails. Counting the face values of two dice would also be discrete, because there are only a limited number of outcomes. Indeed, counting anything would be considered discrete because there are only a finite number of possibilities, with no values in-between. In all these cases, we can consider the outcome of the experiment<a class="footnote-reference brackets" href="#probexp" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> to be a random variable governed by some discrete probability distribution.</p>
<p>The textbook example of this is counting the number of heads after flipping a coin multiple times. For instance, if we flipped a coin 20 times then the probability of different numbers of <em>heads</em> can be described by the <em>binomial</em> distribution. If <span class="math notranslate nohighlight">\(y\)</span> is the count of the number of <em>heads</em>, then <span class="math notranslate nohighlight">\(y\)</span> is a random variable drawn from the binomial distribution, which we write as</p>
<div class="math notranslate nohighlight">
\[
y \sim \mathcal{B}\left(n,p\right).
\]</div>
<p>The shape of the distribition is controlled by two <em>parameters</em>, <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(p\)</span>. In this example, <span class="math notranslate nohighlight">\(n\)</span> is the number of coin flips and <span class="math notranslate nohighlight">\(p\)</span> is the probability of <em>heads</em> on a single flip. So, here <span class="math notranslate nohighlight">\(n = 20\)</span> and (assuming the coin is fair) <span class="math notranslate nohighlight">\(p = 0.5\)</span>. Knowing these parameter values allows us to know everything we need to about the behaviour of <span class="math notranslate nohighlight">\(y\)</span>.</p>
<div class="tip admonition">
<p class="admonition-title">What is a Parameter?</p>
<p>A <em>parameter</em> is simply a number, but one which has a particular <em>importance</em> for understanding some system. In the context of probability distributions, the parameters are numbers that control the <em>shape</em> of the distribution. We typically conceptualise a probability distribution as representing some <em>population</em>, where the parameters are constants that describe the behaviour of that population. As such, the parameters carry great importance for understanding the variable we are measuring. The primary aim of any parametric statistical analysis is to estimate the parameters of the population distribution. Once these values are known, we known everything we need to about the variable in question.</p>
</div>
<p>We can use <code class="docutils literal notranslate"><span class="pre">R</span></code> to simulate realisations of this random variable</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">666</span><span class="p">)</span>
<span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rbinom</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="o">=</span><span class="m">0.5</span><span class="p">)</span>
<span class="n">y</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>12</li><li>8</li><li>14</li><li>8</li><li>9</li><li>11</li><li>14</li><li>10</li><li>5</li><li>9</li></ol>
</div></div>
</div>
<p>which we can think of 10 repeats of flipping a coin 20 times and counting the number of heads. The first time we do this, we get <span class="math notranslate nohighlight">\(\frac{12}{20}\)</span> heads, the second time we get <span class="math notranslate nohighlight">\(\frac{8}{20}\)</span> heads and so on. Notice that we have no real way of knowing what the next value will be and thus, in the short-term, the variable <span class="math notranslate nohighlight">\(y\)</span> is unpredictable. However, in the long-term, we know how frequently certain values will appear and thus there is a much more general sense of predictability.</p>
<p>We can visualise the complete distribution <span class="math notranslate nohighlight">\(\mathcal{B}\left(20,0.5\right)\)</span> using the code below. You can play around with the values of <code class="docutils literal notranslate"><span class="pre">n</span></code> and <code class="docutils literal notranslate"><span class="pre">p</span></code> to see how the distribution changes shape.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Binomial probabilities</span>
<span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">20</span>
<span class="n">p</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.5</span>
<span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">dbinom</span><span class="p">(</span><span class="m">0</span><span class="o">:</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>

<span class="c1"># Plot</span>
<span class="nf">par</span><span class="p">(</span><span class="n">cex.lab</span><span class="o">=</span><span class="m">1.3</span><span class="p">,</span><span class="w"> </span><span class="n">cex.axis</span><span class="o">=</span><span class="m">1.1</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="o">=</span><span class="m">1.4</span><span class="p">)</span><span class="w"> </span><span class="c1"># plot scaling</span>
<span class="nf">barplot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">names.arg</span><span class="o">=</span><span class="m">0</span><span class="o">:</span><span class="n">n</span><span class="p">,</span><span class="w"> </span>
<span class="w">        </span><span class="n">main</span><span class="o">=</span><span class="nf">paste0</span><span class="p">(</span><span class="s">&quot;Binomial Distribution (n=&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="s">&quot; p=&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;)&quot;</span><span class="p">),</span><span class="w"> </span>
<span class="w">        </span><span class="n">xlab</span><span class="o">=</span><span class="s">&quot;Number of Heads&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="s">&quot;Probability&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;skyblue&quot;</span><span class="p">,</span><span class="w"> </span>
<span class="w">        </span><span class="n">border</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/28f1d14afc9c2992e2fe887b032db671fb51d4481fadf8a547fbd6eaf628768a.png"><img alt="_images/28f1d14afc9c2992e2fe887b032db671fb51d4481fadf8a547fbd6eaf628768a.png" src="_images/28f1d14afc9c2992e2fe887b032db671fb51d4481fadf8a547fbd6eaf628768a.png" style="width: 840px; height: 480px;" /></a>
</div>
</div>
<p>Although experimental psychologists do not spend much time flipping coins, we need to think more generally about the utility of probability distributions. For instance, imagine an experiment where each subject completes a number of trials. After each trial, their response can be categorised in one of two ways. Over all the trials we sum the number of times their response is in one category rather than the other. In this example, the measurement could be considered a binomial random variable, with <span class="math notranslate nohighlight">\(n\)</span> equal to the number of trials and <span class="math notranslate nohighlight">\(p\)</span> unknown. The purpose of the experiment is then to estimate what <span class="math notranslate nohighlight">\(p\)</span> might be and, potentially, how <span class="math notranslate nohighlight">\(p\)</span> changes under different manipulations.</p>
<p>Other examples of discrete probability distributions include the <a class="reference external" href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli distribution</a>, <a class="reference external" href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson distribution</a> and the <a class="reference external" href="https://en.wikipedia.org/wiki/Negative_binomial_distribution">negative binomial distribution</a>.</p>
<div class="important admonition">
<p class="admonition-title">Treating Discrete as Continuous</p>
<p>In many real-world cases of discrete random variables, you may find them being treated as <em>continuous</em> for the purpose of statistical analysis. For instance, the binomial distribution shown above <em>could</em> be approximated by a normal distribution. Historically, psychologists do this frequently when dealing with discrete data, such as the scores from a questionnaire or counts of the number of items remembered after a memory test. An argument can be made that the underlying structure that we are measuring is continuous and thus a predicted questionnaire score of <code class="docutils literal notranslate"><span class="pre">5.324</span></code> or quoting <code class="docutils literal notranslate"><span class="pre">7.235</span></code> items remembered are meaningful representation of the <em>latent variable</em> that is being captured. However, in many cases, this is done simply because psychologists are not well-trained on how to deal with discrete outcomes and so often simply ignore the true nature of what they are measuring. To become a powerful researcher in experimental psychology, it is important that this sort of information is <em>not</em> ignored and that the data are treated appropriately.</p>
</div>
</section>
<section id="continuous-random-variables">
<h3>Continuous Random Variables<a class="headerlink" href="#continuous-random-variables" title="Link to this heading">#</a></h3>
<p>The second class of random variables concern those where the number of possible values is <em>infinte</em>. This can either be within an <em>unbounded</em> range (so the values can span <span class="math notranslate nohighlight">\(-\infty\)</span> to <span class="math notranslate nohighlight">\(\infty\)</span>), or within a <em>bounded</em> range (such as anything between 0 and 1).</p>
<p>In many real-world situations our measurements are continuous and so treating the outcomes of experiments as <em>continuous</em> random variables is common. Indeed, huge amount of statistical theory are exclusively dedicated to continuous random variables. As an example, measuring the <em>height</em> of females in the UK could be conceptualised as a random variable drawn from a <em>normal</em> distribution. If <span class="math notranslate nohighlight">\(y\)</span> is the measurement of <em>height</em>, we would write</p>
<div class="math notranslate nohighlight">
\[
y \sim \mathcal{N}\left(\mu,\sigma^{2}\right).
\]</div>
<p>Like the binomial distribution, the shape of the normal distribution is controlled by two parameters. The first is the <em>mean</em> (denoted <span class="math notranslate nohighlight">\(\mu\)</span>), which controls the value that the distribution is centred-on. The second is the <em>variance</em> (denoted <span class="math notranslate nohighlight">\(\sigma^{2}\)</span>), which controls the <em>width</em> of the distribution and thus how much values drawn from the distribution will differ from the mean.</p>
<p>For the example of <em>height</em>, we could set <span class="math notranslate nohighlight">\(\mu = 162\)</span> and <span class="math notranslate nohighlight">\(\sigma^{2} = 6^{2} = 36\)</span>, both measured in centimetres. We could then use <code class="docutils literal notranslate"><span class="pre">R</span></code> to simulate realisations of this random variable using the <code class="docutils literal notranslate"><span class="pre">rnorm</span></code> function<a class="footnote-reference brackets" href="#rnorm" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="m">162</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="nf">sqrt</span><span class="p">(</span><span class="m">36</span><span class="p">))</span>
<span class="n">y</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>166.550377068006</li><li>154.16288844593</li><li>157.184882587777</li><li>151.246554993233</li><li>161.747805275864</li><li>174.900255707068</li><li>151.378614970781</li><li>167.187921567392</li><li>151.679064611033</li><li>162.804754008847</li></ol>
</div></div>
</div>
<p>which we can think of as measuring the height of 10 random females in the UK. We can also visualise the distribution <span class="math notranslate nohighlight">\(\mathcal{N}\left(162,36\right)\)</span> using the code below. Again, you can play around with the values of <code class="docutils literal notranslate"><span class="pre">mean</span></code> and <code class="docutils literal notranslate"><span class="pre">sd</span></code> to see how the distribution changes shape.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Normal parameters</span>
<span class="n">mean</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">162</span>
<span class="n">sd</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">36</span><span class="p">)</span>

<span class="c1"># Generate x values (+/- 4 SDs from the mean)</span>
<span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="n">mean</span><span class="m">-4</span><span class="o">*</span><span class="n">sd</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="m">+4</span><span class="o">*</span><span class="n">sd</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="o">=</span><span class="m">1000</span><span class="p">)</span>

<span class="c1"># Calculate the normal density</span>
<span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="n">sd</span><span class="p">)</span>

<span class="c1"># Plot</span>
<span class="nf">par</span><span class="p">(</span><span class="n">cex.lab</span><span class="o">=</span><span class="m">1.3</span><span class="p">,</span><span class="w"> </span><span class="n">cex.axis</span><span class="o">=</span><span class="m">1.1</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="o">=</span><span class="m">1.4</span><span class="p">)</span><span class="w"> </span><span class="c1"># plot scaling</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;l&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">,</span>
<span class="w">     </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">paste0</span><span class="p">(</span><span class="s">&quot;Normal Distribution (μ = &quot;</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;, σ = &quot;</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;)&quot;</span><span class="p">),</span>
<span class="w">     </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Height&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Probability Density&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/c1a9e1797276545c61ebdd791b39cf16378880725deeddb58710a89352b7997e.png"><img alt="_images/c1a9e1797276545c61ebdd791b39cf16378880725deeddb58710a89352b7997e.png" src="_images/c1a9e1797276545c61ebdd791b39cf16378880725deeddb58710a89352b7997e.png" style="width: 840px; height: 480px;" /></a>
</div>
</div>
<p>Like the example earlier, it is unlikely that, as an experimental psychologist, you would spend much time measuring people’s <em>height</em>. However, thinking more generally, you might end up measuring <em>reaction time</em>, scores from a <em>visual analogue scale</em>, <em>IQ</em>, metrics derived from <em>eye-tracking</em> or <em>time spent</em> attending to a visual stimulus. These are all examples of measures that can, in theory, take an infinite number of values within a given range and thus are all examples of continuous random variables.</p>
<p>Although the normal distribution is used most frequently, other examples of continuous probability distributions include the <a class="reference external" href="https://en.wikipedia.org/wiki/Gamma_distribution">gamma distribution</a>, <a class="reference external" href="https://en.wikipedia.org/wiki/Log-normal_distribution">log-normal distribution</a> and the <a class="reference external" href="https://en.wikipedia.org/wiki/Continuous_uniform_distribution">uniform distribution</a>.</p>
<div class="tip admonition">
<p class="admonition-title">The Core Assumptions of an Experiment</p>
<p>When we conduct an experiment, we concptualise the variables that we are measuring as <em>random variables</em>. This means that their values will change with each measurement and are governed by some random process. In this context, <em>random</em> means that their behaviour adheres to some probability distribution. As such, the variance in our measurements contains a known structure in terms of the underlying probability distribution. Our experiment is then conceptualised as the process of making random draws from that distribution. The shape of the distribution is governed by a number of <em>parameters</em>, which are conceptualised as <em>fixed constants</em> of the population we are drawing samples from. Our aim, very generally, is to use the information in the sample to estimate those population parameter values. This is how a statistical model attempts to explain the seemingly random variations in real-world measurements.</p>
</div>
</section>
</section>
<section id="the-expected-value-of-a-distribution">
<h2>The Expected Value of a Distribution<a class="headerlink" href="#the-expected-value-of-a-distribution" title="Link to this heading">#</a></h2>
<p>All distributions have a property known as the <em>expected value</em>. Informally, this is equivalent to the <em>mean</em> of the distribution and thus it tells us the value that we <em>expect</em>, on average. More formally, the expected value is a form of <em>weighted-average</em>, where each value is weighted by its probability. However, the precise mathematical definition is not really important for our purposes. Instead, we just need to understand the term conceptually. For instance, if we have a random variable <span class="math notranslate nohighlight">\(y\)</span> that adheres to</p>
<div class="math notranslate nohighlight">
\[
y \sim \mathcal{N}\left(\mu,\sigma^{2}\right),
\]</div>
<p>then the mathematical definition of the expected value results in</p>
<div class="math notranslate nohighlight">
\[
E\left(y\right) = \mu.
\]</div>
<p>As such, our <em>expectation</em> for any realisation of <span class="math notranslate nohighlight">\(y\)</span> would be equal to the mean of the distribution. This is an obvious example because the normal distribution has an expected value that is equal to one of its parameters. However, the principle is applicable to <em>any</em> distribution, whether its mean is coded directly by one of the parameters or not. For instance, if we had</p>
<div class="math notranslate nohighlight">
\[
y \sim \mathcal{B}\left(n,p\right)
\]</div>
<p>then the expected value of <span class="math notranslate nohighlight">\(y\)</span> turns out to be</p>
<div class="math notranslate nohighlight">
\[
E\left(y\right) = np.
\]</div>
<p>You can verify this by looking at the distribution we visualised earlier.</p>
</section>
<section id="the-variance-of-a-distribution">
<h2>The Variance of a Distribution<a class="headerlink" href="#the-variance-of-a-distribution" title="Link to this heading">#</a></h2>
<p>As well as an expected value, all distributions have some concept of <em>variance</em>. Informally, this captures the <em>width</em> of the distribution and thus dictates the degree to which we expect our measurements to deviate from the expected value, on average. This tells us how <em>consistent</em> the data are with the expected value. Much like the expected value, the variance of a specific distribution is captured using some function of the parameters. In the case of the normal distribution we have</p>
<div class="math notranslate nohighlight">
\[
y \sim \mathcal{N}\left(\mu,\sigma^{2}\right),
\]</div>
<p>and the variance is simply</p>
<div class="math notranslate nohighlight">
\[
\text{Var}\left(y\right) = \sigma^{2}.
\]</div>
<p>Again, this is fairly obvious. If instead we have</p>
<div class="math notranslate nohighlight">
\[
y \sim \mathcal{B}\left(n,p\right)
\]</div>
<p>then the variance of <span class="math notranslate nohighlight">\(y\)</span> turns out to be</p>
<div class="math notranslate nohighlight">
\[
\text{Var}\left(y\right) = np\left(1-p\right),
\]</div>
<p>which is much less obvious. Whether the variance is clearly coded in the parameters of the distribution or not, the important point is that <em>all</em> distributions contain some metric of variance.</p>
<div class="tip admonition">
<p class="admonition-title">Equations for the Expected Value and Variance</p>
<p>If you are ever curious, the <a class="reference external" href="https://en.wikipedia.org/wiki/Probability_distribution">Wikipedia pages</a> for all the most common probability distributions contain tables giving the formulas for their various properties, including the mean and variance. For some distributions, the mean and variance are more obviously coded within their parameters (e.g. the normal distribution, the Poisson distribution), whereas for others these properties are more complex functions of the parameters (e.g. the binomial distribution, the uniform distribution).</p>
</div>
</section>
<section id="why-are-the-expected-value-and-variance-important">
<h2>Why are the Expected Value and Variance Important?<a class="headerlink" href="#why-are-the-expected-value-and-variance-important" title="Link to this heading">#</a></h2>
<p>At the beginning of this lesson, we discussed the concept of variance as an informal description of what we could see when we plotted some data. Although useful, this could not be used to <em>explain</em> or <em>predict</em> the data, it just quantified what we already knew. In order to explain and predict the data, we need some mathematical description of the <em>data-generating process</em>. This is precisely what a probability distribution does. Furthermore, the properties of the <em>expected value</em> and the <em>variance</em> allow us to partion the data-generating process into those elements that are <em>predictable</em> and those elements that are <em>unpredictable</em>.</p>
<p>With this in mind, the expected value captures the element of the data-generating process that is <em>predictable</em>. The expected value is not subject to random variation, meaning that it is the element of the distribution that <em>does not change</em> across measurements. The expected value can therefore be thought of as representing some <em>universal truth</em> of the variable in question. Because of this, we can conceptualise any realisation of a random variable as the expected value plus some random variation</p>
<div class="math notranslate nohighlight">
\[
y_{i} = E\left(y\right) + \epsilon_{i}.
\]</div>
<p>Here, <span class="math notranslate nohighlight">\(\epsilon_{i}\)</span> is the <span class="math notranslate nohighlight">\(i\)</span>th <em>error</em>, conceptualised as the difference between the value we expected and the actual value of <span class="math notranslate nohighlight">\(y_{i}\)</span>. In other words</p>
<div class="math notranslate nohighlight">
\[
\epsilon_{i} = y_{i} - E\left(y\right).
\]</div>
<div class="tip admonition">
<p class="admonition-title">Understanding Indices</p>
<p>In the equation above we used <span class="math notranslate nohighlight">\(y_{i}\)</span> to indicate a non-specific instance of the random variable <span class="math notranslate nohighlight">\(y\)</span>. The little <span class="math notranslate nohighlight">\(i\)</span> is known as an <em>index</em>. It is a short-hand way of expressing “any value of <span class="math notranslate nohighlight">\(y\)</span>”. Typically, the range of the index would be indicated using an expression such as <span class="math notranslate nohighlight">\(i = 1, \dots, n\)</span>, which just tells us that <span class="math notranslate nohighlight">\(i\)</span> can take any value between 1 and <span class="math notranslate nohighlight">\(n\)</span>, where <span class="math notranslate nohighlight">\(n\)</span> is the total number of datapoints. It is effectively a short way of writing</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
y_{1} &amp;= E\left(y\right) + \epsilon_{1} \\
y_{2} &amp;= E\left(y\right) + \epsilon_{2} \\
y_{3} &amp;= E\left(y\right) + \epsilon_{3} \\
\vdots                     \\
y_{n} &amp;= E\left(y\right) + \epsilon_{n}. \\
\end{align*}
\end{split}\]</div>
<p>As we can see, whenever we use an index we are actually inferring that there are <em>multiple</em> equations across the range of the index. The important thing to note is that terms with an index will change across the equations, whereas terms <em>without</em> an index remain constant. Because of this, we can already infer from the expression</p>
<div class="math notranslate nohighlight">
\[
y_{i} = E\left(y\right) + \epsilon_{i}
\]</div>
<p>that <span class="math notranslate nohighlight">\(E\left(y\right)\)</span> is the same across all the equations, whereas <span class="math notranslate nohighlight">\(y_{i}\)</span> and <span class="math notranslate nohighlight">\(\epsilon_{i}\)</span> can change.</p>
<p>A connection can be made here with programming in <code class="docutils literal notranslate"><span class="pre">R</span></code>, as this is much the same as typing <code class="docutils literal notranslate"><span class="pre">y[1]</span></code> or <code class="docutils literal notranslate"><span class="pre">y[2]</span></code>, where the value in brackets is the <em>index</em> of the variable <code class="docutils literal notranslate"><span class="pre">y</span></code>. We can think of <span class="math notranslate nohighlight">\(y_{i}\)</span> as akin to using <code class="docutils literal notranslate"><span class="pre">y[i]</span></code> in a loop, where the variable <code class="docutils literal notranslate"><span class="pre">i</span></code> could refer to any index from 1 through to <span class="math notranslate nohighlight">\(n\)</span>. As such, we can think of the mathematical expression above as being akin to the code</p>
<div class="highlight-R notranslate"><div class="highlight"><pre><span></span><span class="kr">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">n</span><span class="p">){</span>
<span class="w">    </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">error</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>which we know is short for</p>
<div class="highlight-R notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">error</span><span class="p">[</span><span class="m">1</span><span class="p">]</span>
<span class="n">y</span><span class="p">[</span><span class="m">2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">error</span><span class="p">[</span><span class="m">2</span><span class="p">]</span>
<span class="n">y</span><span class="p">[</span><span class="m">3</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">error</span><span class="p">[</span><span class="m">3</span><span class="p">]</span>
<span class="n">y</span><span class="p">[</span><span class="m">4</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">error</span><span class="p">[</span><span class="m">4</span><span class="p">]</span>
<span class="kc">...</span>
</pre></div>
</div>
</div>
<p>To understand this notion of the expected values and the errors more clearly, take the random variable</p>
<div class="math notranslate nohighlight">
\[
y_{i} \sim \mathcal{N}\left(\mu,\sigma^{2}\right)
\]</div>
<p>with <span class="math notranslate nohighlight">\(\mu = 2\)</span> and <span class="math notranslate nohighlight">\(\sigma^{2} = 1\)</span>. Imagine that the first value we sampled <span class="math notranslate nohighlight">\((i=1)\)</span> was equal to 5. Because <span class="math notranslate nohighlight">\(E(y) = \mu\)</span>, we can think of this as being the mean plus some random variation</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
y_{1} &amp;= \mu + \epsilon_{1} \\
      &amp;= 2 + 3 \\ 
      &amp;= 5.
\end{align*}
\end{split}\]</div>
<p>Imagine that the second value we sampled <span class="math notranslate nohighlight">\((i=2)\)</span> was then equal to 0.5. We can think of this as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
y_{2} &amp;= \mu + \epsilon_{2} \\ 
      &amp;= 2 + -1.5           \\
      &amp;= 0.5.
\end{align*}
\end{split}\]</div>
<p>So notice that there is an element that is <em>constant</em> across measurements and an element that <em>changes</em> with each measurement. In this way, every single value we measure <em>contains</em> the expected value of the distribution, but has been deflected from the expected value by some random perturbation.</p>
<p>Going back to the idea of capturing the <em>predictable</em> and <em>unpredictable</em> elements of a variable, it is the <em>variance</em> of the distribution that captures this unpredictability. As we have seen, the expected value is not subject to random variation and thus it is considered <em>constant</em> across measurements. Because of this, the expected value cannot be the source of the random variation that we see in real data. As such, the randomness must come from the errors. As we saw above, each measurement we make is associated with the <em>same</em> expected value and a <em>different</em> error. It is therefore <span class="math notranslate nohighlight">\(\epsilon\)</span> that has probabilistic behaviour. This means that we can express the probability model</p>
<div class="math notranslate nohighlight">
\[
y_{i} \sim \mathcal{N}\left(\mu,\sigma^{2}\right)
\]</div>
<p>as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
y_{i} &amp;= \mu + \epsilon_{i} \\
\epsilon_{i} &amp;\sim \mathcal{N}\left(0,\sigma^{2}\right)
\end{align*}
\end{split}\]</div>
<p>Thus, the random behaviour of <span class="math notranslate nohighlight">\(y\)</span> can be split into a non-random part (<span class="math notranslate nohighlight">\(\mu\)</span>) and a random part (<span class="math notranslate nohighlight">\(\epsilon\)</span>). Because it is considered a random variable, this means that <span class="math notranslate nohighlight">\(\epsilon\)</span> has a probability distribution identical to <span class="math notranslate nohighlight">\(y\)</span>, but with a change of expectation.</p>
<p>We can illustrate this in <code class="docutils literal notranslate"><span class="pre">R</span></code> by removing the expected value from the data and visualising the distribution. When we do this, all that happens is that we centre the data around 0. Importantly, we do not remove any of the randomness. Using <code class="docutils literal notranslate"><span class="pre">mpg</span></code> as an example, we have</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">par</span><span class="p">(</span><span class="n">mfrow</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">2</span><span class="p">),</span><span class="w"> </span><span class="n">mar</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">5</span><span class="p">,</span><span class="m">5</span><span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="m">2</span><span class="p">))</span>
<span class="nf">par</span><span class="p">(</span><span class="n">cex.lab</span><span class="o">=</span><span class="m">1.1</span><span class="p">,</span><span class="w"> </span><span class="n">cex.axis</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="o">=</span><span class="m">1.1</span><span class="p">)</span><span class="w"> </span><span class="c1"># plot scaling</span>

<span class="n">mpg</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mtcars</span><span class="o">$</span><span class="n">mpg</span>
<span class="n">err</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mtcars</span><span class="o">$</span><span class="n">mpg</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">mtcars</span><span class="o">$</span><span class="n">mpg</span><span class="p">)</span>
<span class="n">n</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">mpg</span><span class="p">)</span>

<span class="nf">hist</span><span class="p">(</span><span class="n">mpg</span><span class="p">,</span><span class="w"> </span><span class="n">breaks</span><span class="o">=</span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">&quot;MPG&quot;</span><span class="p">,</span><span class="w">        </span><span class="n">main</span><span class="o">=</span><span class="s">&quot;Raw Data&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;skyblue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">border</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">)</span>
<span class="nf">hist</span><span class="p">(</span><span class="n">err</span><span class="p">,</span><span class="w"> </span><span class="n">breaks</span><span class="o">=</span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">&quot;MPG - Mean&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s">&quot;Errors&quot;</span><span class="p">,</span><span class="w">   </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;skyblue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">border</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">)</span>

<span class="nf">plot</span><span class="p">(</span><span class="n">mpg</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">&quot;Car&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="s">&quot;MPG&quot;</span><span class="p">,</span><span class="w">        </span><span class="n">main</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">)</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">err</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">&quot;Car&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="s">&quot;MPG - Mean&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/054b9e72c8d15c51853b2285190d91a76ada6cbd10ef37e425d880363ba927fa.png"><img alt="_images/054b9e72c8d15c51853b2285190d91a76ada6cbd10ef37e425d880363ba927fa.png" src="_images/054b9e72c8d15c51853b2285190d91a76ada6cbd10ef37e425d880363ba927fa.png" style="width: 840px; height: 480px;" /></a>
</div>
</div>
<p>So notice that both the <em>errors</em> and the <em>raw data</em> have <em>the same form of distribution</em>. The only element that changes is that the mean of the error distribution is 0. We will see the importance of this as we progress on this unit, as many elements of statistical modelling concern themseleves with the behaviour of the <em>errors</em> and not the raw data.</p>
<p>From the plots above, we can see that the errors indicate the degree to which the data deviate from their expectation. Any error with a magnitude of 0 does not deviate from the expectation, whereas an error with a magnitude of 10 (for example) indicates that a particular datapoint was 10 units away from where we expected it to be. The errors therefore capture the <em>variance</em> of the random variable in question. As such, the total variation in <span class="math notranslate nohighlight">\(y\)</span> can be broken into two sources. The first is the expected value, which is <em>constant</em> across all the values, and the second is the <em>error</em>, which indicates the degree to which the data deviates from the expected value. The expected value influence how <em>predictable</em> the data are and the errors influence how <em>unpredictable</em> the data are. This is the <em>centre</em> and the <em>width</em> of the assumed probability distribution that generated the data.</p>
<p>This can all be made clearer by considering the <em>actual</em> formal definition of variance:</p>
<div class="math notranslate nohighlight">
\[
\text{Var}\left(y\right) = E\left[\left(y - E\left[y\right]\right)^{2}\right]
\]</div>
<p>As we know, subtracting the expected value from the data gives us the <em>errors</em>, meaning we can rewrite the variance as</p>
<div class="math notranslate nohighlight">
\[
\text{Var}\left(y\right) = E\left(\epsilon^{2}\right).
\]</div>
<p>So the variance is really the expected value of the squared errors. In other word, the <em>mean</em> of the squared errors. This fits precisely with our concept of variance from earlier. The difference now is that this metric is defined in reference to the assumed distribution of the data. Rather than just being a simple description of what we could see when we plotted the data, we now have a <em>mathematical model of the data-generating process</em>. Depending upon the accuracy of this model, we can now say where that data came from and can also make prediction about what values it may have in the future.</p>
<aside class="topic">
<p class="topic-title">What do you now know?</p>
<p>In this section, we have explored the important concept of <em>random variables</em>, <em>probability distributions</em>, and the most useful properties of those distributions. After reading this section, you should have a good sense of:</p>
<ul class="simple">
<li><p>What a <em>random variable</em> is, particularly in terms of the difference between <em>discrete</em> and <em>continuous</em> random variables.</p></li>
<li><p>The notation used to express a random variable in relation to its distribution, such as <span class="math notranslate nohighlight">\(y \sim \mathcal{B}(n,p)\)</span>.</p></li>
<li><p>What a <em>parameter</em> is in relation to a probability distribution and why it is important.</p></li>
<li><p>What the <em>expected value</em> of a distribution is, the notation for expressing the expected value and why it is important.</p></li>
<li><p>What the <em>variance</em> of a distribution is, the notation for expressing the variance and why it is important.</p></li>
<li><p>How indices are used in notation to denote different values.</p></li>
<li><p>The concept of splitting every measured value in its expectation and error, with the errors having the same distributional form as the raw data, but with a mean of 0.</p></li>
</ul>
</aside>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="probexp" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Note that an “experiment” in the context of probability theory has a much broader definition than we would typically use in science.</p>
</aside>
<aside class="footnote brackets" id="rnorm" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">rnorm</span></code> function parameterises the normal distribution using the <em>standard deviation</em>, rather than the <em>variance.</em></p>
</aside>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="1.understanding-variance.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Understanding Variance</p>
      </div>
    </a>
    <a class="right-next"
       href="3.define-stat-models.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Defining a Statistical Model</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-variables">Random Variables</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-random-variables">Discrete Random Variables</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-random-variables">Continuous Random Variables</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-expected-value-of-a-distribution">The Expected Value of a Distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-variance-of-a-distribution">The Variance of a Distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-are-the-expected-value-and-variance-important">Why are the Expected Value and Variance Important?</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr Martyn McFarquhar & Dr George Farmer
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>